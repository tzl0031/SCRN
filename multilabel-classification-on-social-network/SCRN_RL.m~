function [pred_label,accuracy]= SCRN_RL(Net,IDX,Label,SF,maxiter)
numNodes = size(Net,1);
tr_IDX = IDX.training;
inference_IDX = IDX.inference;
test_IDX = IDX.testing;
tr_label = Label(tr_IDX,:);
test_label = Label(test_IDX,:);
inference_label = Label(inference_IDX,:);
SF_tr = SF(tr_IDX,:);
SF_inference = SF(inference_IDX,:);

[numtr,numf] = size(SF_tr); % the dimension of the node's social features
numClass = size(tr_label,2); % the number of class
num_inference = size(inference_label,1);


%% Initializing the feature vector for each class
Class_feature = zeros(numClass,numf);
for i=1:numClass
    member = (tr_label(:,i)==1);
    Class_feature(i,:) = sum(SF_tr(member,:),1);
end

%% Calculate the initial class propagation probability for testing node
method = 'hist';
Prob_cp = Calc_prob_cp(SF_inference, Class_feature, method);

%% SCRN start
iter = 1;
output = sparse(numNodes,numClass); % the output prob. for all nodes
output(tr_IDX,:) = tr_label;
old_label = sparse(num_inference,numClass);
pred_label = sparse(num_inference,numClass);

% The default parameters setting for relaxation labeling 
changed = num_inference; % the number test nodes changed
belta = 0.5;
alpha = 0.99;
P_total_old = sparse(num_inference,numClass);
while(iter <= maxiter && changed >= 0) 
    P = zeros(num_inference,numClass);
    tmp = 0;
    for i = 1:num_inference
        tmp = find(Net(inference_IDX(i),:)>0); % find the node's neighbors
        if size(tmp) ~= 0
            a = 1;
        end
        Node_sim = 'Degree'; % the method for calculating the similarity between node and its neighbors
        Sim = Calc_nodeW(Net,inference_IDX(i),tmp,Node_sim); 
        P(i,:) = Sim*(repmat(Prob_cp(i,:),length(tmp),1).* output(tmp,:));
        if(sum(P(i,:)))
            P(i,:) = P(i,:)/sum(P(i,:));
        end
        clear tmp;
    end 
    
    % Relaxation Labeling 
    P_total_new = belta*P + (1-belta)*P_total_old;
    tp = inference_IDX(find(sum(P_total_new,2)));
    tp2 = (sum(P_total_new,2)>0);
    P_total_new(tp2,:) = P_total_new(tp2,:)./repmat(sum(P_total_new(tp2,:),2),1,numClass);
    
    % Keep the predictions probability of the testing nodes according to the # of labels each test node could belong.
    method2 = 'all'; %'all','top'
    [output(tp,:),pred_label(tp2,:)] = Keep_prediction(P_total_new(tp2,:),Label(tp,:),method2);
    clear P2;
    changed = full(sum(sum(xor(pred_label,old_label))));
    fprintf('%d iteration, # of prediction changed = %d\n',iter,changed);
   
    %% Evaluation on the whole inference set
%     rate(1) = evaluation(pred_label,inference_label,numClass,'Macro');
%     rate(2) = evaluation(pred_label,inference_label,numClass,'Micro');
%     fprintf('%d iteration, Macro = %d; Micro = %d \n',iter,rate(1),rate(2));
    %% update the Class feature----weighted sum
    Class_feature = zeros(numClass,numf);
    for i = 1:numClass
        member = (output(:,i)>0);
        Class_feature(i,:) = output(member,i)'*SF(member,:);
        Class_feature(i,:) = Class_feature(i,:)./length(member);
    end
    %% (1) update the testing nodes' class propagation probability
    Prob_cp = Calc_prob_cp(SF_inference,Class_feature, method);
    old_label = pred_label;
    iter = iter +1;
    P_total_old = P_total_new;
    belta = belta*alpha;
end
%% Evaluate on the testing set
[C,I1] = intersect(inference_IDX,test_IDX);
pred_label = pred_label(I1,:);
accuracy(1) = evaluation(pred_label,test_label, "micro");
accuracy(2) = evaluation(pred_label,test_label, "macro");
% fprintf(accuracy(1));
% fprintf(accuracy(2));
fprintf('# %d iteration, micro accuracy is %f : \n', iter, accuracy(1));
fprintf('# %d iteration, macro accuracy is %f : \n', iter, accuracy(2));
end





